{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import  BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬取https://suzhou.8684.cn/list1所有公交信息\n",
      "爬取https://suzhou.8684.cn/list2所有公交信息\n",
      "爬取https://suzhou.8684.cn/list3所有公交信息\n",
      "爬取https://suzhou.8684.cn/list4所有公交信息\n",
      "爬取https://suzhou.8684.cn/list5所有公交信息\n",
      "爬取https://suzhou.8684.cn/list6所有公交信息\n",
      "爬取https://suzhou.8684.cn/list7所有公交信息\n",
      "爬取https://suzhou.8684.cn/list8所有公交信息\n",
      "爬取https://suzhou.8684.cn/list9所有公交信息\n",
      "爬取https://suzhou.8684.cn/listC所有公交信息\n",
      "爬取https://suzhou.8684.cn/listD所有公交信息\n",
      "爬取https://suzhou.8684.cn/listG所有公交信息\n",
      "爬取https://suzhou.8684.cn/listH所有公交信息\n",
      "爬取https://suzhou.8684.cn/listK所有公交信息\n",
      "爬取https://suzhou.8684.cn/listM所有公交信息\n",
      "爬取https://suzhou.8684.cn/listO所有公交信息\n",
      "爬取https://suzhou.8684.cn/listS所有公交信息\n",
      "爬取https://suzhou.8684.cn/listT所有公交信息\n",
      "爬取https://suzhou.8684.cn/listW所有公交信息\n",
      "爬取https://suzhou.8684.cn/listX所有公交信息\n",
      "爬取https://suzhou.8684.cn/listY所有公交信息\n",
      "爬取https://suzhou.8684.cn/listZ所有公交信息\n"
     ]
    }
   ],
   "source": [
    "\n",
    "items=[]\n",
    "headers={\n",
    "    'user_agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/17.17134',\n",
    "}\n",
    "def parse_navigation():\n",
    "    url='https://suzhou.8684.cn/'\n",
    "    r=requests.get(url=url,headers=headers)\n",
    "    #解析内容，获取所有链接\n",
    "    soup=BeautifulSoup(r.text,'lxml')\n",
    "    #以数字开头的所有链接\n",
    "    number_list=[]\n",
    "    number_href_list=soup.find('div',class_='bus_kt_r1').find_all('a')\n",
    "    for i in range(len(number_href_list)):\n",
    "        number_list.append(number_href_list[i]['href'])\n",
    "        \n",
    "    #以字母开头的所有链接\n",
    "    letter_list=[]\n",
    "    letter_href_list=soup.find('div',class_='bus_kt_r2').find_all('a')\n",
    "    for i in range(len(letter_href_list)):\n",
    "        letter_list.append(letter_href_list[i]['href'])\n",
    "        \n",
    "    return number_list+letter_list\n",
    "    \n",
    "\n",
    "def parse_erji(navi_list):\n",
    "    #遍历上面的列表，依次发送请求，获取所有的二级页面\n",
    "    for first_url in navi_list:\n",
    "        first_url='https://suzhou.8684.cn'+first_url\n",
    "        print('爬取%s所有公交信息'%first_url)\n",
    "        r=requests.get(url=first_url,headers=headers)\n",
    "        #解析内容,获取每一路公交的url\n",
    "        parse_erji_route(r.text)\n",
    "        \n",
    "def parse_erji_route(content):\n",
    "    soup=BeautifulSoup(content,'lxml')\n",
    "    #获取每一个线路\n",
    "    route_list=soup.find('div',id='con_site_1').find_all('a')\n",
    "    \n",
    "    #遍历列表\n",
    "    for route in route_list:\n",
    "        route='https://suzhou.8684.cn'+route['href']\n",
    "        r= requests.get(url=route,headers=headers)\n",
    "        #解析内容，获取每一路公交的详细信息\n",
    "        parse_sanji_route(r.text)\n",
    "\n",
    "def parse_sanji_route(content):\n",
    "    soup=BeautifulSoup(content,'lxml')\n",
    "    #获取公交车具体内容\n",
    "    bus_number=soup.find('div',class_='bus_i_t1').h1.text\n",
    "    run_time=soup.find('p',class_='bus_i_t4').text\n",
    "    ticket_info=soup.find_all('p',class_='bus_i_t4')[1].text\n",
    "    gxsj=soup.find_all('p',class_='bus_i_t4')[3].text\n",
    "    #获取站名\n",
    "    zhanming1=soup.find('div',class_='bus_site_layer').find_all('div')\n",
    "    zhanming_list=[]\n",
    "    for zhanming in zhanming1:\n",
    "        zhanming=zhanming.a.text\n",
    "        zhanming_list.append(zhanming)\n",
    "    \n",
    "    #将每一条公交信息放到字典中\n",
    "    item={\n",
    "        '线路名':bus_number,\n",
    "        '运行时间':run_time,\n",
    "        '票价信息':ticket_info,\n",
    "        '更新时间':gxsj,\n",
    "        '站点名称':zhanming_list\n",
    "    }\n",
    "    items.append(item)\n",
    "    \n",
    "def main():\n",
    "    #爬取第一页导航信息\n",
    "    navi_list=parse_navigation()\n",
    "    #爬取二级页码，需要找到所有以1.2.3···A.B.C···开头的公交页面\n",
    "    parse_erji(navi_list)\n",
    "    #爬取完毕\n",
    "    fp=open('苏州公交.txt','w',encoding='utf8')\n",
    "    for item in items:\n",
    "        fp.write(str(item)+'\\n')\n",
    "        \n",
    "    fp.close()\n",
    "   \n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
